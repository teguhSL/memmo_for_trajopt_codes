{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import openravepy\n",
    "import trajoptpy\n",
    "import json\n",
    "import numpy as np\n",
    "import trajoptpy.kin_utils as ku\n",
    "from trajoptpy.check_traj import traj_is_safe\n",
    "import humanoidspy\n",
    "import time\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from trajopt_util import *\n",
    "from planning_util import *\n",
    "from regression import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "FILENAME = 'data/atlas_planning/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the trajopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "env = openravepy.Environment()\n",
    "env.StopSimulation()\n",
    "env.Load(\"../bigdata/atlas.xml\")\n",
    "env.Load(\"../env/bookshelves.env.xml\")\n",
    "env.SetDefaultViewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = env.GetRobots()[0]        \n",
    "init_transform = np.eye(4)\n",
    "init_transform[:3,3] = [-.35, 1, .92712]\n",
    "init_transform[:3,3] = [-0.15, 0., .92712]\n",
    "#init_transform[:3,3] = [2.6, 1, .92712]\n",
    "robot.SetTransform(init_transform)\n",
    "\n",
    "robot.SetDOFValues([-1.3],[robot.GetJoint(\"l_arm_shx\").GetDOFIndex()])\n",
    "robot.SetDOFValues([1.3],[robot.GetJoint(\"r_arm_shx\").GetDOFIndex()])\n",
    "standing_posture = robot.GetActiveDOFValues()\n",
    "\n",
    "dof = robot.GetActiveDOF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_skeleton(n_steps):\n",
    "    request = {\n",
    "        \"basic_info\" : {\n",
    "            \"n_steps\" : n_steps,\n",
    "            \"manip\" : \"active\",\n",
    "            \"start_fixed\" : True\n",
    "        },\n",
    "        \"costs\" : [\n",
    "        {\n",
    "            \"type\" : \"joint_vel\",            \n",
    "            \"params\": {\"coeffs\":([.1]*14 + [.05]*14)}\n",
    "        },\n",
    "        {\n",
    "            \"type\":\"collision\",\n",
    "            \"params\":{\"coeffs\":[2], \"dist_pen\":[.005], \"continuous\":False}\n",
    "        },\n",
    "        {\n",
    "            \"type\":\"collision\",\"name\":\"cont_coll\",\n",
    "            \"params\":{\"coeffs\":[2], \"dist_pen\":[.005], \"continuous\":True}\n",
    "        }\n",
    "        ],\n",
    "        \"constraints\" : [\n",
    "        ],\n",
    "        \"init_info\" : {\n",
    "            \"type\" : \"stationary\"\n",
    "        }\n",
    "    }\n",
    "    for i in xrange(1,n_steps):\n",
    "        request[\"costs\"].extend([\n",
    "         #{\n",
    "             #\"type\":\"potential_energy\",\n",
    "             #\"params\":{\"coeff\" : .0005,\"timestep\":i}\n",
    "         #},\n",
    "        #{\n",
    "            #\"type\":\"static_torque\",\n",
    "            #\"params\":{\"coeff\" : .01,\"timestep\":i}\n",
    "        #}                    \n",
    "        ])\n",
    "    return request  \n",
    "\n",
    "def press_button_request(robot, hand_xyz, hand_link, foot_links, n_steps):\n",
    "    \"\"\"\n",
    "    Sets up the problem to safely shift the weight to the other foot (to_foot)\n",
    "    Suppose to_foot = \"r_foot\"    \n",
    "    Then problem constrains both feet to remain at fixed poses (their current poses)\n",
    "    at all intermediate timesteps, the center of mass lies over the convex hull of l_foot and r_foot\n",
    "    at the final timestep, the center of mass lies over r_foot\n",
    "    \"\"\"    \n",
    "    \n",
    "    from_foot, to_foot = foot_links\n",
    "    \n",
    "    request = request_skeleton(n_steps)\n",
    "    from_foot_xyz, from_foot_quat = xyzQuatFromMatrix(robot.GetLink(from_foot).GetTransform())\n",
    "    to_foot_xyz, to_foot_quat = xyzQuatFromMatrix(robot.GetLink(to_foot).GetTransform())\n",
    "    \n",
    "    for i in xrange(1, n_steps):\n",
    "        request[\"constraints\"].extend([\n",
    "            {\n",
    "                \"type\":\"pose\",\n",
    "                \"name\":\"from_foot_pose\",\n",
    "                \"params\":{\n",
    "                    \"xyz\":list(from_foot_xyz),\n",
    "                    \"wxyz\":list(from_foot_quat),\n",
    "                    \"link\":from_foot,\n",
    "                    \"timestep\":i\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\":\"pose\",\n",
    "                \"name\":\"to_foot_pose\",\n",
    "                \"params\":{\n",
    "                    \"xyz\":list(to_foot_xyz),\n",
    "                    \"wxyz\":list(to_foot_quat),\n",
    "                    \"link\":to_foot,\n",
    "                    \"timestep\":i\n",
    "                }\n",
    "            }\n",
    "        ])    \n",
    "        request[\"constraints\"].append(\n",
    "            {\n",
    "                \"type\":\"zmp\",\"name\":\"zmp_%i\"%i,\n",
    "                \"params\":{\"planted_links\":[from_foot, to_foot],\"timestep\":i}\n",
    "            })\n",
    "    request[\"constraints\"].append(\n",
    "        {\n",
    "            \"type\":\"pose\",\n",
    "            \"name\":\"final_hand_pose\",\n",
    "            \"params\":{\n",
    "                \"xyz\":list(hand_xyz),\n",
    "                \"wxyz\":[0.5*np.sqrt(2),0,0,0.5*np.sqrt(2)],\n",
    "                \"link\":hand_link,\n",
    "                \"pos_coeffs\":[1,1,1],\n",
    "                \"rot_coeffs\":[0.0,0.0,0.0],\n",
    "                \"timestep\":i\n",
    "            }\n",
    "        }        \n",
    "    )\n",
    "\n",
    "    return request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_traj_atlas(result, target, threshold = 0.01):\n",
    "    traj = result.GetTraj()\n",
    "    #check for collision\n",
    "    if traj_is_safe(traj, robot) is not True:\n",
    "        print \"There is a collision within the trajectory!\"\n",
    "        return False\n",
    "\n",
    "    #check target for pose constraints\n",
    "    robot.SetActiveDOFValues(traj[-1])\n",
    "    xyz = robot.GetLink('r_hand').GetTransform()[0:3,3]\n",
    "    if (np.linalg.norm(xyz - target) > threshold):\n",
    "        print('Target is not reached!')\n",
    "        return False\n",
    "\n",
    "    print 'Optimization is success!'\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_valid_xyz(limits):\n",
    "    is_success = False\n",
    "\n",
    "    while is_success is not True:\n",
    "        x,y,z = generate_random_xyz(limits)\n",
    "        #create a box and check for collision\n",
    "        is_col = check_col_with_box(env,x,y,z)\n",
    "        if is_col:\n",
    "            #print('There is collision!')\n",
    "            continue\n",
    "        else:\n",
    "            #print('No collision!')\n",
    "            is_success = True\n",
    "    \n",
    "    return x,y,z\n",
    "\n",
    "def xyzQuatFromMatrix(T):\n",
    "    wxyz_xyz = openravepy.poseFromMatrix(T)\n",
    "    return wxyz_xyz[4:7], wxyz_xyz[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build / Retrieve Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_database(x_init, y_init, num_traj, limits, n_steps = 30,predictor=None):\n",
    "    num_plan = 0\n",
    "    comp_times = []\n",
    "    costs = []\n",
    "    tic = time.time()\n",
    "    \n",
    "    while len(x_init) < num_traj:\n",
    "        print('{}th Planning, {} trajectories in database'.format(num_plan,len(x_init)))\n",
    "        #Get a random pose as target\n",
    "        init_joint = standing_posture.copy()\n",
    "        robot.SetActiveDOFValues(init_joint)\n",
    "        xyz_target = generate_valid_xyz(limits)\n",
    "        robot.SetActiveDOFValues(init_joint)\n",
    "\n",
    "        \n",
    "        request_standard = press_button_request(robot, xyz_target, \"r_hand\", [\"l_foot\",\"r_foot\"],n_steps)\n",
    "        duration, result = run_opt(request_standard, env)\n",
    "   \n",
    "        #Check traj result\n",
    "        traj = result.GetTraj()\n",
    "        if check_traj_atlas(result, xyz_target):\n",
    "            print 'Planning is successfull!'\n",
    "            x_init.append(xyz_target)\n",
    "            y_init.append(traj.flatten())\n",
    "            comp_times.append(duration)\n",
    "            costs.append(result.GetCosts()[0][1])\n",
    "        else:\n",
    "            print('Fail to find good solution!') \n",
    "\n",
    "        num_plan += 1\n",
    "        \n",
    "        \n",
    "    #Store the result\n",
    "    toc = time.time()\n",
    "    total_time = toc-tic\n",
    "    success_rate = num_traj*1.0/num_plan\n",
    "    x_init = np.vstack(x_init)\n",
    "    y_init = np.vstack(y_init)\n",
    "    \n",
    "    \n",
    "    data = dict()\n",
    "    data['x'] = x_init\n",
    "    data['y'] = y_init\n",
    "    data['total_time'] = total_time\n",
    "    data['success_rate'] = success_rate\n",
    "    data['comp_times'] = comp_times\n",
    "    data['costs'] = costs\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_build_database = False\n",
    "to_augment_database = True\n",
    "num_traj = 1\n",
    "n_steps = 10\n",
    "limits = [[0.3, 0.7],[-0.5, 0.5],[0.8,1.4]]\n",
    "\n",
    "if to_build_database:\n",
    "    if to_augment_database:\n",
    "        #load data\n",
    "        data = pickle.load( open(FILENAME + 'data.pkl', 'rb'))\n",
    "        x_init = list(data['x'])\n",
    "        y_init = list(data['y'])\n",
    "        num_traj += len(x_init)     \n",
    "    else:\n",
    "        x_init,y_init = [],[]\n",
    "        \n",
    "    data = build_database(x_init, y_init, num_traj,limits, n_steps = n_steps)\n",
    "    x_init = data['x']\n",
    "    y_init = data['y']\n",
    "    pickle.dump(data,open(FILENAME + 'data.pkl', 'wb') )\n",
    "    print('Success_rate : {}, average costs:{}'.format(data['success_rate'], np.mean(data['costs'])))\n",
    "else:\n",
    "    #load data\n",
    "    data = pickle.load( open(FILENAME + 'data.pkl', 'rb'))\n",
    "    x_init = data['x']\n",
    "    y_init = data['y']\n",
    "    num_traj = len(x_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = x_init[0:1000]\n",
    "y_init = y_init[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Dimensionality Reduction to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "y_pca = PCA(n_components = 50)\n",
    "y_pca.fit(y_init)\n",
    "y_init_reduced = y_pca.transform(y_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Function Approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input = len(x_init[0])\n",
    "is_load_regressor = False\n",
    "\n",
    "nn = NN_Regressor()\n",
    "gpy = GPy_Regressor(dim_input = dim_input)\n",
    "gpy_pca = GPy_Regressor(dim_input = dim_input, is_transform='PCA')\n",
    "dpglm = DP_GLM_Regressor()\n",
    "dpglm_pca = DP_GLM_Regressor(is_transform='PCA')\n",
    "\n",
    "if is_load_regressor:\n",
    "    nn.load_from_file(FILENAME + 'nn')\n",
    "    gpy.load_from_file(FILENAME + 'gpy')\n",
    "    gpy_pca.load_from_file(FILENAME + 'gpy_pca')\n",
    "    dpglm.load_from_file(FILENAME + 'dpglm')\n",
    "    dpglm_pca.load_from_file(FILENAME + 'dpglm_pca')\n",
    "else:\n",
    "    print 'Planning for NN'\n",
    "    nn.fit(x_init, y_init)\n",
    "    nn.save_to_file(FILENAME + 'nn')\n",
    "\n",
    "    print 'Planning for GPY'\n",
    "    gpy.fit(x_init, y_init, num_restarts=10)\n",
    "    gpy.save_to_file(FILENAME + 'gpy')\n",
    "    \n",
    "    print 'Planning for GPY PCA'\n",
    "    gpy_pca.fit(x_init, y_init_reduced)\n",
    "    gpy_pca.save_to_file(FILENAME + 'gpy_pca')\n",
    "\n",
    "    \n",
    "    print 'Planning for DPGLM'\n",
    "    dpglm.fit(x_init,y_init)\n",
    "    dpglm.save_to_file(FILENAME + 'dpglm')\n",
    "\n",
    "    print 'Planning for DPGLM PCA'\n",
    "    dpglm_pca.fit(x_init,y_init_reduced)\n",
    "    dpglm_pca.save_to_file(FILENAME + 'dpglm_pca')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the warmstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating the test cases\n",
    "create_test = True\n",
    "if create_test:\n",
    "    x_test = []\n",
    "    target_joints = []\n",
    "    num_test = 300\n",
    "    for i in range(num_test):\n",
    "        init_joint = standing_posture.copy()\n",
    "        robot.SetActiveDOFValues(init_joint)\n",
    "        xyz_target = generate_valid_xyz(limits)\n",
    "        robot.SetActiveDOFValues(init_joint)\n",
    "        cur_x = xyz_target\n",
    "        x_test.append(cur_x)\n",
    "\n",
    "    x_test = np.vstack(x_test)\n",
    "    data_test = dict()\n",
    "    data_test['x_test'] = x_test\n",
    "    test_file = open(FILENAME + 'data_test.npy', 'wb')\n",
    "    pickle.dump( data_test,test_file)\n",
    "    test_file.close()\n",
    "else:\n",
    "    #load data\n",
    "    test_file = open(FILENAME + 'data_test.npy', 'rb')\n",
    "    data_test = pickle.load(test_file)\n",
    "    x_test = data_test['x_test']\n",
    "    num_test = len(x_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_init(request, init_type, init_values):\n",
    "    request[\"init_info\"][\"type\"] = \"given_traj\"\n",
    "\n",
    "    if init_type == 'straight':\n",
    "        request['init_info']['endpoint'] = init_values.tolist()\n",
    "    elif init_type == 'given_traj':\n",
    "        request[\"init_info\"][\"data\"] = [row.tolist() for row in init_values]\n",
    "    else:\n",
    "        print('Initialization {} is not defined'.format(init_type))\n",
    "        return None\n",
    "    return request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "method_names = ['STD    ',  'NN     ', 'GPY    ', 'BGMR   ', 'GPY_PCA   ', 'BGMR_PCA  ']\n",
    "methods = [nn, gpy, dpglm, gpy_pca, dpglm_pca]\n",
    "results = dict()\n",
    "result,success, duration = dict(),dict(),dict()\n",
    "for method in method_names:\n",
    "    results[method] = dict()\n",
    "    results[method]['costs'] = []\n",
    "    results[method]['successes'] = []\n",
    "    results[method]['comp_times'] = []\n",
    "    results[method]['func_evals'] = []\n",
    "    results[method]['qp_solves'] = []\n",
    "    \n",
    "num_test = 250\n",
    "ik_times = []\n",
    "quat = [1,0,0,0]\n",
    "for i in range(num_test):\n",
    "    print('{}th Planning'.format(i))\n",
    "    \n",
    "    #setting up the problem case\n",
    "    #index = np.random.randint(0,len(x_test))\n",
    "    index = i\n",
    "    x_cur = x_test[index:index+1,:]\n",
    "    xyz_target = x_cur.flatten()\n",
    "    robot.SetActiveDOFValues(init_joint)\n",
    "    \n",
    "    #without warmstart\n",
    "    method_name = method_names[0]\n",
    "    request_standard = press_button_request(robot, xyz_target, \"r_hand\", [\"l_foot\",\"r_foot\"],n_steps)\n",
    "    duration[method_name], result[method_name] = run_opt(request_standard, env)\n",
    "    success[method_name] = check_traj_atlas(result[method_name],xyz_target)\n",
    "    \n",
    "    \n",
    "    #Other warmstart methods\n",
    "    for i,method in enumerate(methods):\n",
    "        method_name = method_names[i+1]\n",
    "        if isinstance(method, Straight_Regressor):\n",
    "            traj,cov = method.predict(init_joint0, target_joint)\n",
    "        elif isinstance(method, DP_GLM_Regressor):\n",
    "            traj,cov = method.predict(x_cur, return_gmm = True)\n",
    "        else:\n",
    "            traj,cov = method.predict(x_cur)\n",
    "            \n",
    "        if method.is_transform == 'PCA':\n",
    "            traj = y_pca.inverse_transform(traj)\n",
    "        traj = traj.reshape(-1,dof)\n",
    "        traj[0,:] = init_joint\n",
    "        robot.SetActiveDOFValues(init_joint)\n",
    "        request_traj = press_button_request(robot, xyz_target, \"r_hand\", [\"l_foot\",\"r_foot\"],n_steps)\n",
    "        request_traj = set_init(request_traj, 'given_traj', traj)\n",
    "        duration[method_name], result[method_name] = run_opt(request_traj, env)    \n",
    "        success[method_name] = check_traj_atlas(result[method_name],xyz_target)\n",
    "    #Record the result\n",
    "    for method_name in method_names:\n",
    "        results[method_name]['costs'].append(result[method_name].GetCosts()[0][1])\n",
    "        results[method_name]['func_evals'].append(result[method_name].GetNumFuncEval()[0])\n",
    "        results[method_name]['qp_solves'].append(result[method_name].GetNumQPSolve()[0])\n",
    "        results[method_name]['successes'].append(success[method_name])      \n",
    "        results[method_name]['comp_times'].append(duration[method_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(' Method \\t| Success Rate \\t| Conv. Time \\t| Traj. Cost \\t| Func. Evals \\t| QP Solves')\n",
    "for method in method_names:\n",
    "    successes = np.array(results[method]['successes'])\n",
    "    success = np.count_nonzero(successes)\n",
    "    \n",
    "    comp_times = np.array(results[method]['comp_times'])[successes]\n",
    "    costs = np.array(results[method]['costs'])[successes]\n",
    "    func_evals = np.array(results[method]['func_evals'])[successes]\n",
    "    qp_solves = np.array(results[method]['qp_solves'])[successes]\n",
    "    \n",
    "    print('{0}: \\t& {1:.3f} \\t& {2:.2f} \\t& {3:.3f}  \\\\\\\\'.format(method, success*1.0/len(successes), np.sum(comp_times)/success, np.sum(costs)/success))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Results Tied to Standard Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(' Method \\t| Success Rate \\t| Conv. Time \\t| Traj. Cost \\t| Func. Evals \\t| QP Solves')\n",
    "standard_successes = np.array(results['STD    ']['successes'])\n",
    "\n",
    "for method in method_names:\n",
    "    successes = np.array(results[method]['successes'])[standard_successes]\n",
    "    success = np.count_nonzero(successes)\n",
    "    comp_times = np.array(results[method]['comp_times'])[standard_successes][successes]\n",
    "    costs = np.array(results[method]['costs'])[standard_successes][successes]\n",
    "    func_evals = np.array(results[method]['func_evals'])[standard_successes][successes]\n",
    "    qp_solves = np.array(results[method]['qp_solves'])[standard_successes][successes]\n",
    "    \n",
    "    print('{0}: \\t {1:.3f} \\t {2:.2f} \\t {3:.3f} \\t {4:.3f} \\t {5:.3f}'.format(method, success*1.0/len(successes), np.sum(comp_times)/success, np.sum(costs)/success, 1.0*np.sum(func_evals)/success, 1.0*np.sum(qp_solves)/success ))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
