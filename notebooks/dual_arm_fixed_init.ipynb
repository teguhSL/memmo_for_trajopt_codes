{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openravepy\n",
    "import trajoptpy\n",
    "import json\n",
    "import numpy as np\n",
    "import trajoptpy.kin_utils as ku\n",
    "from trajoptpy.check_traj import traj_is_safe\n",
    "import time\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from trajopt_util import *\n",
    "from planning_util import *\n",
    "from regression import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "FILENAME = 'data/dual_arm_fixed_init/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the trajopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "env = openravepy.Environment()\n",
    "env.StopSimulation()\n",
    "env.Load(\"robots/pr2-beta-static.zae\")\n",
    "env.Load(\"../env/bookshelves.env.xml\")\n",
    "env.SetDefaultViewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = env.GetRobots()[0]\n",
    "left_arm = robot.GetManipulator(\"leftarm\")\n",
    "right_arm = robot.GetManipulator(\"rightarm\")\n",
    "\n",
    "robot.SetActiveDOFs(np.r_[right_arm.GetArmIndices(), left_arm.GetArmIndices()])\n",
    "coeffs = [1,1,1,1,1,1,1,  1,1,1,1,1,1,1,] #coefficients for joint velocity cost\n",
    "\n",
    "dof = len(robot.GetActiveDOFValues())\n",
    "left_dof_away = np.array([ 0.5646,  1.1371, -0.65  , -2.1172,  2.0552, 0.99, -2.168 ])\n",
    "right_dof_away = np.array([ -0.5646,  1.1371, 0.65  , -2.1172,  2.0552, 0.99, -2.168 ])\n",
    "robot.SetDOFValues(left_dof_away, left_arm.GetArmIndices())\n",
    "robot.SetDOFValues(right_dof_away, right_arm.GetArmIndices())\n",
    "init_joint0 = robot.GetActiveDOFValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the IK Solver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmat_target = np.array([[ 0.9689,  0.    , -0.2474,  0.4918],\n",
    "       [-0.    ,  1.    ,  0.    ,  0.912 ],\n",
    "       [ 0.2474, -0.    ,  0.9689,  0.8947],\n",
    "       [ 0.    ,  0.    ,  0.    ,  1.    ]])\n",
    "quat_target = openravepy.quatFromRotationMatrix(hmat_target).tolist()\n",
    "xyz_target = hmat_target[0:3,3].tolist()\n",
    "\n",
    "# BEGIN IK for all manips\n",
    "manips = [left_arm,right_arm]\n",
    "for manip in manips:\n",
    "    robot.SetActiveManipulator(manip)\n",
    "    ikmodel = openravepy.databases.inversekinematics.InverseKinematicsModel(\n",
    "        robot, iktype=openravepy.IkParameterization.Type.Transform6D)\n",
    "    if not ikmodel.load():\n",
    "        ikmodel.autogenerate()   \n",
    "    \n",
    "target_joint = ku.ik_for_link(hmat_target, left_arm, \"l_gripper_tool_frame\",\n",
    "    filter_options = openravepy.IkFilterOptions.CheckEnvCollisions)\n",
    "# END ik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a random problem "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from planning_util import *\n",
    "limits = dict()\n",
    "limits[0] = [[0.47, 0.8],[-0.5, 0.5],[0.3,1.4]]\n",
    "for i in range(1):\n",
    "    _,_,_,_,target_joint = get_random_pose_both(env,limits, right_arm, left_arm)\n",
    "    robot.SetActiveDOFValues(target_joint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build / Retrieve Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_database(x_init, y_init, num_traj, limits, n_steps = 30, predictor=None):\n",
    "    num_plan = 0\n",
    "    comp_times = []\n",
    "    costs = []\n",
    "\n",
    "    tic = time.time()\n",
    "    while len(x_init) < num_traj:\n",
    "        print('{}th Planning, {} trajectories in database'.format(num_plan,len(x_init)))\n",
    "        #Get a random pose as target\n",
    "        target_joint_right,xyz_target_right,target_joint_left, \\\n",
    "                            xyz_target_left,target_joint = get_random_pose_both(env,limits,right_arm,left_arm)\n",
    "        robot.SetActiveDOFValues(target_joint)\n",
    "        \n",
    "        #Build memory using a set of predictors\n",
    "        for func in predictor:\n",
    "            #Predict the warmstart\n",
    "            x_cur = np.concatenate([target_joint])[None,:]\n",
    "            if isinstance(func, Straight_Regressor):\n",
    "                traj,_ = func.predict(init_joint0, target_joint)     \n",
    "            else:\n",
    "                traj,_ = func.predict(x_cur)\n",
    "                \n",
    "            if func.is_transform == 'PCA':\n",
    "                traj = func.pca.inverse_transform(traj)\n",
    "            \n",
    "            traj = traj.reshape(-1,dof)\n",
    "            traj[0,:] = init_joint0\n",
    "            \n",
    "            #Plan\n",
    "            robot.SetActiveDOFValues(init_joint0)\n",
    "            request_traj = define_request(time_step=n_steps, coeffs = coeffs,init_type='given_traj',constraint_type='joint')\n",
    "            request_traj = add_constraint(request_traj, 'joint', '', target_joint,-1)\n",
    "            request_traj = set_init(request_traj, 'given_traj', traj)\n",
    "            duration, result = run_opt(request_traj, env)    \n",
    "\n",
    "            #Check traj result\n",
    "            traj = result.GetTraj()\n",
    "            if check_traj(env,result, target_joint):\n",
    "                print 'Planning is successfull!'\n",
    "                x_init.append(np.concatenate(x_cur))\n",
    "                y_init.append(traj.flatten())\n",
    "                comp_times.append(duration)\n",
    "                costs.append(result.GetCosts()[0][1])\n",
    "                break\n",
    "            else:\n",
    "                print('Fail to find good solution!')\n",
    "                continue        \n",
    "\n",
    "        num_plan += 1\n",
    "        \n",
    "    \n",
    "    #Store the result\n",
    "    toc = time.time()\n",
    "    total_time = toc-tic\n",
    "    success_rate = num_traj*1.0/num_plan\n",
    "    x_init = np.vstack(x_init)\n",
    "    y_init = np.vstack(y_init)\n",
    "    \n",
    "    data = dict()\n",
    "    data['x'] = x_init\n",
    "    data['y'] = y_init\n",
    "    data['total_time'] = total_time\n",
    "    data['success_rate'] = success_rate\n",
    "    data['comp_times'] = comp_times\n",
    "    data['costs'] = costs\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_build_database = True\n",
    "to_augment_database = False\n",
    "num_traj = 500\n",
    "n_steps = 30\n",
    "limits = dict()\n",
    "limits[0] = [[0.47, 0.8],[-0.5, 0.5],[0.3,1.4]]\n",
    "\n",
    "#build using straight-line warm-start\n",
    "straight = Straight_Regressor(dof = dof, n_steps = n_steps)\n",
    "\n",
    "if to_build_database:\n",
    "    if to_augment_database:\n",
    "        #load data\n",
    "        data = pickle.load( open(FILENAME + 'data.pkl', 'rb'))\n",
    "        x_init = list(data['x'])\n",
    "        y_init = list(data['y'])\n",
    "        num_traj += len(x_init)     \n",
    "    else:\n",
    "        x_init,y_init = [],[]\n",
    "        \n",
    "    data = build_database(x_init, y_init, num_traj,limits, n_steps = n_steps, predictor=[straight])\n",
    "    x_init = data['x']\n",
    "    y_init = data['y']\n",
    "    pickle.dump(data,open(FILENAME + 'data.pkl', 'wb') )\n",
    "    print('Success_rate : {}, average costs:{}'.format(data['success_rate'], np.mean(data['costs'])))\n",
    "else:\n",
    "    #load data\n",
    "    data = pickle.load( open(FILENAME + 'data.pkl', 'rb'))\n",
    "    x_init = data['x']\n",
    "    y_init = data['y']\n",
    "    num_traj = len(x_init)\n",
    "    print('Obtain {} trajectories'.format(num_traj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the data sample"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_init = x_init[0:200]\n",
    "y_init = y_init[0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Dimensionality Reduction to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "y_pca = PCA(n_components = 50)\n",
    "y_pca.fit(y_init)\n",
    "y_init_reduced = y_pca.transform(y_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Database "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(5):\n",
    "    index = np.random.randint(0,len(y_init))\n",
    "    traj = y_init[index:index+1]\n",
    "    traj = traj.reshape(-1,dof)\n",
    "    plot_traj(env,traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Function Approximator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_input = len(x_init[0])\n",
    "is_load_regressor = False\n",
    "\n",
    "straight = Straight_Regressor(dof = dof, n_steps=n_steps)\n",
    "nn = NN_Regressor()\n",
    "gpy = GPy_Regressor(dim_input = dim_input)\n",
    "gpy_pca = GPy_Regressor(dim_input = dim_input, is_transform='PCA')\n",
    "gpy_pca.pca = y_pca\n",
    "bgmr = DP_GLM_Regressor()\n",
    "bgmr_pca = DP_GLM_Regressor(is_transform='PCA')\n",
    "bgmr_pca.pca = y_pca\n",
    "if is_load_regressor:\n",
    "    nn.load_from_file(FILENAME + 'nn')\n",
    "    gpy.load_from_file(FILENAME + 'gpy')\n",
    "    gpy_pca.load_from_file(FILENAME + 'gpy_pca')\n",
    "    bgmr.load_from_file(FILENAME + 'bgmr')\n",
    "    bgmr_pca.load_from_file(FILENAME + 'bgmr_pca')\n",
    "else:\n",
    "    print 'Planning for NN'\n",
    "    nn.fit(x_init, y_init)\n",
    "    nn.save_to_file(FILENAME + 'nn')\n",
    "\n",
    "    print 'Planning for GPY'\n",
    "    gpy.fit(x_init, y_init, num_restarts=10)\n",
    "    gpy.save_to_file(FILENAME + 'gpy')\n",
    "    \n",
    "    print 'Planning for GPY PCA'\n",
    "    gpy_pca.fit(x_init, y_init_reduced)\n",
    "    gpy_pca.save_to_file(FILENAME + 'gpy_pca')\n",
    "\n",
    "    print 'Planning for bgmr'\n",
    "    bgmr.fit(x_init,y_init)\n",
    "    bgmr.save_to_file(FILENAME + 'bgmr')\n",
    "    \n",
    "    print 'Planning for bgmr PCA'\n",
    "    bgmr_pca.fit(x_init,y_init_reduced)\n",
    "    bgmr_pca.save_to_file(FILENAME + 'bgmr_pca')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_test = True\n",
    "\n",
    "if create_test:\n",
    "    x_test = []\n",
    "    target_joints = []\n",
    "    num_test = 500\n",
    "    for i in range(num_test):\n",
    "        target_joint_right,xyz_target_right,target_joint_left,xyz_target_left,target_joint = get_random_pose_both(env,limits,right_arm,left_arm)\n",
    "        robot.SetActiveDOFValues(target_joint)\n",
    "        cur_x = target_joint\n",
    "        x_test.append(cur_x)\n",
    "\n",
    "    x_test = np.vstack(x_test)\n",
    "    data_test = dict()\n",
    "    data_test['x_test'] = x_test\n",
    "    test_file = open(FILENAME + 'data_test.pkl', 'wb')\n",
    "    pickle.dump(data_test,test_file)\n",
    "    test_file.close()\n",
    "else:\n",
    "    #load data\n",
    "    test_file = open(FILENAME + 'data_test.pkl', 'rb')\n",
    "    data_test = pickle.load(test_file)\n",
    "    x_test = data_test['x_test']\n",
    "    num_test = len(x_test)\n",
    "    test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the warmstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = ['STD    ', 'NN     ', 'GPR    ', 'GPR_PCA', 'BGMR', 'BGMR_PCA']\n",
    "methods = [straight, nn, gpy, gpy_pca,  bgmr, bgmr_pca]\n",
    "results = dict()\n",
    "for method in method_names:\n",
    "    results[method] = dict()\n",
    "    results[method]['costs'] = []\n",
    "    results[method]['successes'] = []\n",
    "    results[method]['comp_times'] = []\n",
    "    results[method]['func_evals'] = []\n",
    "    results[method]['qp_solves'] = []\n",
    "    \n",
    "\n",
    "num_test = 250\n",
    "result,success, duration = dict(),dict(),dict()\n",
    "\n",
    "for it in range(num_test):\n",
    "    print('{}th Planning'.format(it))\n",
    "    \n",
    "    #setting up the problem case\n",
    "    #index = np.random.randint(0,len(x_test))\n",
    "    index = it\n",
    "    x_cur = x_test[index:index+1,:]\n",
    "    target_joint = x_cur.copy().flatten()\n",
    "    robot.SetActiveDOFValues(init_joint0)\n",
    "    \n",
    "    #plan with various warmstarts\n",
    "    request_traj = define_request(time_step=n_steps, coeffs = coeffs,init_type='given_traj',constraint_type='joint')\n",
    "    request_traj = add_constraint(request_traj, 'joint', '', target_joint,-1)\n",
    "    \n",
    "    for i,method in enumerate(methods):\n",
    "        method_name = method_names[i]\n",
    "        if isinstance(method, Straight_Regressor):\n",
    "            traj,cov = method.predict(init_joint0, target_joint)\n",
    "        else:\n",
    "            traj,cov = method.predict(x_cur)\n",
    "            \n",
    "        if method.is_transform == 'PCA':\n",
    "            traj = method.pca.inverse_transform(traj)\n",
    "            \n",
    "        traj = traj.reshape(-1,dof)\n",
    "        traj[0,:] = init_joint0\n",
    "        robot.SetActiveDOFValues(init_joint0)\n",
    "        request_traj = set_init(request_traj, 'given_traj', traj)\n",
    "        duration[method_name], result[method_name] = run_opt(request_traj, env)    \n",
    "        success[method_name] = check_traj(env,result[method_name], target_joint)\n",
    "\n",
    "    #Record the result\n",
    "    for method_name in method_names:\n",
    "        results[method_name]['costs'].append(result[method_name].GetCosts()[0][1])\n",
    "        results[method_name]['func_evals'].append(result[method_name].GetNumFuncEval()[0])\n",
    "        results[method_name]['qp_solves'].append(result[method_name].GetNumQPSolve()[0])\n",
    "        results[method_name]['successes'].append(success[method_name])      \n",
    "        results[method_name]['comp_times'].append(duration[method_name])\n",
    "        \n",
    "    print_result(results,method_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(results,open(FILENAME + 'result3.pkl', 'wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load(open(FILENAME + 'result.pkl', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
